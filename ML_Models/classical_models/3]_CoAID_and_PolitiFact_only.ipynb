{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"colab_type":"code","executionInfo":{"elapsed":25793,"status":"ok","timestamp":1598815153946,"user":{"displayName":"Nikhil L Kolluri","photoUrl":"","userId":"01149428014947466640"},"user_tz":300},"id":"0XJf_AUCRQFw","outputId":"efa4108a-7509-4a23-b157-d46d7db05952"},"outputs":[{"name":"stdout","output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":8158,"status":"ok","timestamp":1598815164014,"user":{"displayName":"Nikhil L Kolluri","photoUrl":"","userId":"01149428014947466640"},"user_tz":300},"id":"xgnRz4aORU-W"},"outputs":[],"source":["from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","\n","# Place dataset path here\n","FNNpath = \"../Datasets/FNN Titles/\"\n","CoAIDpath = \"../Datasets/CoAID/\"\n","\n","\n","politiFactFake = pd.read_csv(FNNpath+\"politifact_fake.csv\", usecols=['title'])\n","politiFactFake['label']=0\n","politiFactTrue = pd.read_csv(FNNpath+\"politifact_real.csv\", usecols=['title'], nrows=len(politiFactFake.values))\n","politiFactTrue['label']=1\n","\n","\n","CoAIDFalse = pd.read_csv(CoAIDpath+\"NewsFakeCOVID-19.csv\", usecols=['title'])\n","CoAIDFalse['label']=0\n","CoAIDTrue = pd.read_csv(CoAIDpath+\"NewsRealCOVID-19.csv\", usecols=['title'], nrows=len(CoAIDFalse.values))\n","CoAIDTrue['label']=1\n","\n","\n","dfTotal = pd.concat([politiFactTrue, politiFactFake, CoAIDTrue, CoAIDFalse])\n","X = dfTotal['title'].values\n","y = dfTotal['label'].values\n","\n","X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(\n","  X, y, test_size=0.25, random_state=450)\n","\n","\n","\n","path_external = \"/content/drive/MyDrive/CoVerifi&MedVerifi/\" # Replace with appropriate path\n","validationNewsDF = pd.read_csv(path_external+\"Combined_News.csv\", usecols=['title', 'label'])\n","\n","\n","def binaryLabel(label):\n","  if label == \"TRUE\":\n","    return 1\n","  return 0\n","\n","validationNewsDF['label'] = validationNewsDF['label'].apply(lambda label: binaryLabel(str(label)))\n","\n","validationX = validationNewsDF['title'].values\n","validationX = [one_hot(str(elem),10000) for elem in validationX]\n","validationX = pad_sequences(validationX, padding='post', maxlen=500)\n","validationY = validationNewsDF['label'].values"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":10082,"status":"ok","timestamp":1598815177698,"user":{"displayName":"Nikhil L Kolluri","photoUrl":"","userId":"01149428014947466640"},"user_tz":300},"id":"g_BglzZnRYTn","outputId":"8f94973f-755b-444c-99dc-372396ca74f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["CoAID_and_PolitiFact_only: Results of SVM internal validation:\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.58      0.64       246\n","           1       0.66      0.77      0.71       256\n","\n","    accuracy                           0.68       502\n","   macro avg       0.68      0.68      0.67       502\n","weighted avg       0.68      0.68      0.67       502\n","\n","CoAID_and_PolitiFact_only: Results of SVM external validation, on our new dataset:\n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.63      0.66      3883\n","           1       0.60      0.68      0.63      3175\n","\n","    accuracy                           0.65      7058\n","   macro avg       0.65      0.65      0.65      7058\n","weighted avg       0.66      0.65      0.65      7058\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"name":"stdout","output_type":"stream","text":["CoAID_and_PolitiFact_only: Results of LR internal validation:\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.55      0.61       246\n","           1       0.64      0.75      0.69       256\n","\n","    accuracy                           0.65       502\n","   macro avg       0.66      0.65      0.65       502\n","weighted avg       0.66      0.65      0.65       502\n","\n","CoAID_and_PolitiFact_only: Results of LR external validation, on our new dataset:\n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.62      0.66      3883\n","           1       0.59      0.67      0.63      3175\n","\n","    accuracy                           0.64      7058\n","   macro avg       0.64      0.64      0.64      7058\n","weighted avg       0.65      0.64      0.64      7058\n","\n","CoAID_and_PolitiFact_only: Results of Bernoulli NB internal validation:\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.51      0.61       246\n","           1       0.64      0.84      0.73       256\n","\n","    accuracy                           0.68       502\n","   macro avg       0.70      0.67      0.67       502\n","weighted avg       0.69      0.68      0.67       502\n","\n","CoAID_and_PolitiFact_only: Results of Bernoulli NB external validation, on our new dataset:\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.57      0.64      3883\n","           1       0.58      0.74      0.65      3175\n","\n","    accuracy                           0.65      7058\n","   macro avg       0.66      0.65      0.65      7058\n","weighted avg       0.66      0.65      0.65      7058\n","\n"]}],"source":["#For SVM, LR, and NB, we used the default settings provided in the scikit-learn \n","#For CNN we use the standard implementation with default setting https://github.com/dennybritz/cnn-text-classification-tf\n","#Could just use an out-of-the-box CNN implementation from a TF tutorial\n","# The dennybritz one seems good but I can do it later\n","from sklearn import svm\n","from sklearn.linear_model import LogisticRegression\n","from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.metrics import classification_report\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n","# Bernoulli was best of above\n","import math\n","X_train = [one_hot(str(elem), 10000) for elem in X_train_base]\n","X_test =  [one_hot(str(elem), 10000) for elem in X_test_base]\n","X_train = pad_sequences(X_train, padding='post', maxlen=500)\n","X_test = pad_sequences(X_test, padding='post', maxlen=500)\n","\n","svmClassifier = svm.SVC()\n","svmClassifier.fit(X_train, y_train_base)\n","svmPrediction = svmClassifier.predict(X_test)\n","svmPrediction = [math.floor(0.5+pred) for pred in svmPrediction]\n","print(\"CoAID_and_PolitiFact_only: Results of SVM internal validation:\")\n","print(classification_report(y_test_base, svmPrediction))\n","\n","svmValidationPrediction = svmClassifier.predict(validationX)\n","svmValidationPrediction = [math.floor(0.5+pred) for pred in svmValidationPrediction]\n","print(\"CoAID_and_PolitiFact_only: Results of SVM external validation, on our new dataset:\")\n","print(classification_report(validationY, svmValidationPrediction))\n","\n","\n","\n","X_train = [one_hot(str(elem), 10000) for elem in X_train_base]\n","X_test =  [one_hot(str(elem), 10000) for elem in X_test_base]\n","X_train = pad_sequences(X_train, padding='post', maxlen=500)\n","X_test = pad_sequences(X_test, padding='post', maxlen=500)\n","\n","lrClassifier = LogisticRegression(random_state=0, max_iter=500)\n","lrClassifier.fit(X_train, y_train_base)\n","lrPrediction = lrClassifier.predict(X_test)\n","lrPrediction = [math.floor(0.5+pred) for pred in lrPrediction]\n","print(\"CoAID_and_PolitiFact_only: Results of LR internal validation:\")\n","print(classification_report(y_test_base, lrPrediction))\n","\n","lrValidationPrediction = lrClassifier.predict(validationX)\n","lrValidationPrediction = [math.floor(0.5+pred) for pred in lrValidationPrediction]\n","print(\"CoAID_and_PolitiFact_only: Results of LR external validation, on our new dataset:\")\n","print(classification_report(validationY, lrValidationPrediction))\n","\n","X_train = [one_hot(str(elem), 10000) for elem in X_train_base]\n","X_test =  [one_hot(str(elem), 10000) for elem in X_test_base]\n","X_train = pad_sequences(X_train, padding='post', maxlen=500)\n","X_test = pad_sequences(X_test, padding='post', maxlen=500)\n","\n","bnbClassifier = BernoulliNB()\n","bnbClassifier.fit(X_train, y_train_base)\n","bnbPrediction = bnbClassifier.predict(X_test)\n","bnbPrediction = [math.floor(0.5+pred) for pred in bnbPrediction]\n","print(\"CoAID_and_PolitiFact_only: Results of Bernoulli NB internal validation:\")\n","print(classification_report(y_test_base, bnbPrediction))\n","bnbValidationPrediction = bnbClassifier.predict(validationX)\n","bnbValidationPrediction = [math.floor(0.5+pred) for pred in bnbValidationPrediction]\n","print(\"CoAID_and_PolitiFact_only: Results of Bernoulli NB external validation, on our new dataset:\")\n","print(classification_report(validationY, bnbValidationPrediction))\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMflt82xUP5qn+tIRaHHU0F","name":"3]_CoAID_and_PolitiFact_only","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
