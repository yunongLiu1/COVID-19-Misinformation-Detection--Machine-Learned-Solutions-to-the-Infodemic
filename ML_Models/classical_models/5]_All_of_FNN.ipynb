{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":809,"status":"ok","timestamp":1598815989540,"user":{"displayName":"Nikhil L Kolluri","photoUrl":"","userId":"01149428014947466640"},"user_tz":300},"id":"hY13Um5omQs8","outputId":"3dd42126-b0bc-4a4b-df63-ae1cff786b49"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":1938,"status":"ok","timestamp":1598815993817,"user":{"displayName":"Nikhil L Kolluri","photoUrl":"","userId":"01149428014947466640"},"user_tz":300},"id":"MhOtLv90mU9h"},"outputs":[],"source":["from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","\n","# Place dataset path here\n","FNNpath = \"../Datasets/FNN Titles/\"\n","CoAIDpath = \"../Datasets/CoAID/\"\n","\n","\n","politiFactFake = pd.read_csv(FNNpath+\"politifact_fake.csv\", usecols=['title'])\n","politiFactFake['label']=0\n","gossipCopFake = pd.read_csv(FNNpath+\"gossipcop_fake.csv\", usecols=['title'])\n","gossipCopFake['label']=0\n","politiFactTrue = pd.read_csv(FNNpath+\"politifact_real.csv\", usecols=['title'], nrows=len(politiFactFake.values))\n","politiFactTrue['label']=1\n","gossipCopTrue = pd.read_csv(FNNpath+\"gossipcop_real.csv\", usecols=['title'],  nrows=len(gossipCopFake.values))\n","gossipCopTrue['label']=1\n","\n","\n","\n","dfTotal = pd.concat([politiFactTrue, gossipCopTrue, politiFactFake, gossipCopFake])\n","X = dfTotal['title'].values\n","y = dfTotal['label'].values\n","\n","X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(\n","  X, y, test_size=0.25, random_state=450)\n","\n","\n","\n","path_external = \"/content/drive/MyDrive/CoVerifi&MedVerifi/\" # Replace with appropriate path\n","validationNewsDF = pd.read_csv(path_external+\"Combined_News.csv\", usecols=['title', 'label'])\n","\n","\n","def binaryLabel(label):\n","  if label == \"TRUE\":\n","    return 1\n","  return 0\n","\n","validationNewsDF['label'] = validationNewsDF['label'].apply(lambda label: binaryLabel(str(label)))\n","\n","validationX = validationNewsDF['title'].values\n","validationX = [one_hot(str(elem),10000) for elem in validationX]\n","validationX = pad_sequences(validationX, padding='post', maxlen=500)\n","validationY = validationNewsDF['label'].values"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":142047,"status":"ok","timestamp":1598816140481,"user":{"displayName":"Nikhil L Kolluri","photoUrl":"","userId":"01149428014947466640"},"user_tz":300},"id":"TTJuJBZ2mZdm","outputId":"a9e3dc1a-f055-4189-fb61-dacd5508281e"},"outputs":[{"name":"stdout","output_type":"stream","text":["All_of_FNN: Results of SVM internal validation:\n","              precision    recall  f1-score   support\n","\n","           0       0.52      0.59      0.56      1430\n","           1       0.54      0.46      0.50      1448\n","\n","    accuracy                           0.53      2878\n","   macro avg       0.53      0.53      0.53      2878\n","weighted avg       0.53      0.53      0.53      2878\n","\n","All_of_FNN: Results of SVM external validation, on our new dataset:\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.55      0.54      3883\n","           1       0.43      0.41      0.42      3175\n","\n","    accuracy                           0.49      7058\n","   macro avg       0.48      0.48      0.48      7058\n","weighted avg       0.49      0.49      0.49      7058\n","\n","All_of_FNN: Results of LR internal validation:\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.40      0.44      1430\n","           1       0.51      0.62      0.56      1448\n","\n","    accuracy                           0.51      2878\n","   macro avg       0.51      0.51      0.50      2878\n","weighted avg       0.51      0.51      0.50      2878\n","\n","All_of_FNN: Results of LR external validation, on our new dataset:\n","              precision    recall  f1-score   support\n","\n","           0       0.63      0.45      0.53      3883\n","           1       0.50      0.68      0.58      3175\n","\n","    accuracy                           0.56      7058\n","   macro avg       0.57      0.57      0.55      7058\n","weighted avg       0.58      0.56      0.55      7058\n","\n","All_of_FNN: Results of Bernoulli NB internal validation:\n","              precision    recall  f1-score   support\n","\n","           0       0.49      0.47      0.48      1430\n","           1       0.50      0.51      0.51      1448\n","\n","    accuracy                           0.49      2878\n","   macro avg       0.49      0.49      0.49      2878\n","weighted avg       0.49      0.49      0.49      2878\n","\n","All_of_FNN: Results of Bernoulli NB external validation, on our new dataset:\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.67      0.67      3883\n","           1       0.60      0.61      0.61      3175\n","\n","    accuracy                           0.64      7058\n","   macro avg       0.64      0.64      0.64      7058\n","weighted avg       0.64      0.64      0.64      7058\n","\n"]}],"source":["#For SVM, LR, and NB, we used the default settings provided in the scikit-learn \n","#For CNN we use the standard implementation with default setting https://github.com/dennybritz/cnn-text-classification-tf\n","#Could just use an out-of-the-box CNN implementation from a TF tutorial\n","# The dennybritz one seems good but I can do it later\n","from sklearn import svm\n","from sklearn.linear_model import LogisticRegression\n","from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.metrics import classification_report\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n","# Bernoulli was best of above\n","import math\n","X_train = [one_hot(str(elem), 10000) for elem in X_train_base]\n","X_test =  [one_hot(str(elem), 10000) for elem in X_test_base]\n","X_train = pad_sequences(X_train, padding='post', maxlen=500)\n","X_test = pad_sequences(X_test, padding='post', maxlen=500)\n","\n","svmClassifier = svm.SVC()\n","svmClassifier.fit(X_train, y_train_base)\n","svmPrediction = svmClassifier.predict(X_test)\n","svmPrediction = [math.floor(0.5+pred) for pred in svmPrediction]\n","print(\"All_of_FNN: Results of SVM internal validation:\")\n","print(classification_report(y_test_base, svmPrediction))\n","\n","svmValidationPrediction = svmClassifier.predict(validationX)\n","svmValidationPrediction = [math.floor(0.5+pred) for pred in svmValidationPrediction]\n","print(\"All_of_FNN: Results of SVM external validation, on our new dataset:\")\n","print(classification_report(validationY, svmValidationPrediction))\n","\n","\n","\n","X_train = [one_hot(str(elem), 10000) for elem in X_train_base]\n","X_test =  [one_hot(str(elem), 10000) for elem in X_test_base]\n","X_train = pad_sequences(X_train, padding='post', maxlen=500)\n","X_test = pad_sequences(X_test, padding='post', maxlen=500)\n","\n","lrClassifier = LogisticRegression(random_state=0, max_iter=500)\n","lrClassifier.fit(X_train, y_train_base)\n","lrPrediction = lrClassifier.predict(X_test)\n","lrPrediction = [math.floor(0.5+pred) for pred in lrPrediction]\n","print(\"All_of_FNN: Results of LR internal validation:\")\n","print(classification_report(y_test_base, lrPrediction))\n","\n","lrValidationPrediction = lrClassifier.predict(validationX)\n","lrValidationPrediction = [math.floor(0.5+pred) for pred in lrValidationPrediction]\n","print(\"All_of_FNN: Results of LR external validation, on our new dataset:\")\n","print(classification_report(validationY, lrValidationPrediction))\n","\n","X_train = [one_hot(str(elem), 10000) for elem in X_train_base]\n","X_test =  [one_hot(str(elem), 10000) for elem in X_test_base]\n","X_train = pad_sequences(X_train, padding='post', maxlen=500)\n","X_test = pad_sequences(X_test, padding='post', maxlen=500)\n","\n","bnbClassifier = BernoulliNB()\n","bnbClassifier.fit(X_train, y_train_base)\n","bnbPrediction = bnbClassifier.predict(X_test)\n","bnbPrediction = [math.floor(0.5+pred) for pred in bnbPrediction]\n","print(\"All_of_FNN: Results of Bernoulli NB internal validation:\")\n","print(classification_report(y_test_base, bnbPrediction))\n","bnbValidationPrediction = bnbClassifier.predict(validationX)\n","bnbValidationPrediction = [math.floor(0.5+pred) for pred in bnbValidationPrediction]\n","print(\"All_of_FNN: Results of Bernoulli NB external validation, on our new dataset:\")\n","print(classification_report(validationY, bnbValidationPrediction))\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMgCvkK2cX89od0EH8ravOd","name":"5]_All_of_FNN","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
