{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"colab_type":"code","executionInfo":{"elapsed":14510,"status":"ok","timestamp":1598814781431,"user":{"displayName":"Nikhil L Kolluri","photoUrl":"","userId":"01149428014947466640"},"user_tz":300},"id":"EAfZ0hprC8vm","outputId":"579ba6cf-bcab-4dd0-a5e5-de5a281ddcbb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":457,"status":"ok","timestamp":1598814849420,"user":{"displayName":"Nikhil L Kolluri","photoUrl":"","userId":"01149428014947466640"},"user_tz":300},"id":"1ZPXNSIiDDRZ"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","\n","\n","# Place dataset path here\n","path = \"../Datasets/CoAID/\"\n","\n","\n","dfTrue = pd.read_csv(path+\"NewsRealCOVID-19.csv\", usecols=['title'], nrows=500)\n","dfTrue['label']=1\n","dfFalse = pd.read_csv(path+\"NewsFakeCOVID-19.csv\", usecols=['title'], nrows=500)\n","dfFalse['label']=0\n","dfTotal = pd.concat([dfTrue, dfFalse])\n","\n","X = dfTotal['title'].values\n","y = dfTotal['label'].values\n","\n","X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(\n","  X, y, test_size=0.25, random_state=450)\n","\n","\n","\n","path_external = \"/content/drive/MyDrive/CoVerifi&MedVerifi/\" # Replace with appropriate path\n","validationNewsDF = pd.read_csv(path_external+\"Combined_News.csv\", usecols=['title', 'label'])\n","\n","\n","def binaryLabel(label):\n","  if label == \"TRUE\":\n","    return 1\n","  return 0\n","\n","validationNewsDF['label'] = validationNewsDF['label'].apply(lambda label: binaryLabel(str(label)))\n","\n","validationX = validationNewsDF['title'].values\n","validationX = [one_hot(str(elem),10000) for elem in validationX]\n","validationX = pad_sequences(validationX, padding='post', maxlen=500)\n","validationY = validationNewsDF['label'].values"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":4274,"status":"ok","timestamp":1598814878921,"user":{"displayName":"Nikhil L Kolluri","photoUrl":"","userId":"01149428014947466640"},"user_tz":300},"id":"hXFjJwA93t4S","outputId":"1b4b3cad-cb7a-41e0-8fb1-78fda34d7bc1"},"outputs":[{"name":"stdout","output_type":"stream","text":["CoAID_only: Results of SVM internal validation:\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.42      0.57       134\n","           1       0.59      0.95      0.72       116\n","\n","    accuracy                           0.66       250\n","   macro avg       0.74      0.68      0.65       250\n","weighted avg       0.76      0.66      0.64       250\n","\n","CoAID_only: Results of SVM external validation, on our new dataset:\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.44      0.58      3883\n","           1       0.57      0.91      0.70      3175\n","\n","    accuracy                           0.65      7058\n","   macro avg       0.71      0.67      0.64      7058\n","weighted avg       0.72      0.65      0.63      7058\n","\n","CoAID_only: Results of LR internal validation:\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.46      0.59       134\n","           1       0.58      0.87      0.70       116\n","\n","    accuracy                           0.65       250\n","   macro avg       0.69      0.67      0.64       250\n","weighted avg       0.70      0.65      0.64       250\n","\n","CoAID_only: Results of LR external validation, on our new dataset:\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.47      0.59      3883\n","           1       0.57      0.84      0.68      3175\n","\n","    accuracy                           0.64      7058\n","   macro avg       0.68      0.66      0.63      7058\n","weighted avg       0.69      0.64      0.63      7058\n","\n","CoAID_only: Results of Bernoulli NB internal validation:\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.46      0.61       134\n","           1       0.60      0.95      0.74       116\n","\n","    accuracy                           0.68       250\n","   macro avg       0.76      0.70      0.67       250\n","weighted avg       0.77      0.68      0.67       250\n","\n","CoAID_only: Results of Bernoulli NB external validation, on our new dataset:\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.45      0.58      3883\n","           1       0.57      0.88      0.69      3175\n","\n","    accuracy                           0.64      7058\n","   macro avg       0.70      0.66      0.63      7058\n","weighted avg       0.71      0.64      0.63      7058\n","\n"]}],"source":["#For SVM, LR, and NB, we used the default settings provided in the scikit-learn \n","#For CNN we use the standard implementation with default setting https://github.com/dennybritz/cnn-text-classification-tf\n","#Could just use an out-of-the-box CNN implementation from a TF tutorial\n","# The dennybritz one seems good but I can do it later\n","from sklearn import svm\n","from sklearn.linear_model import LogisticRegression\n","from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.metrics import classification_report\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n","# Bernoulli was best of above\n","import math\n","X_train = [one_hot(str(elem), 10000) for elem in X_train_base]\n","X_test =  [one_hot(str(elem), 10000) for elem in X_test_base]\n","X_train = pad_sequences(X_train, padding='post', maxlen=500)\n","X_test = pad_sequences(X_test, padding='post', maxlen=500)\n","\n","svmClassifier = svm.SVC()\n","svmClassifier.fit(X_train, y_train_base)\n","svmPrediction = svmClassifier.predict(X_test)\n","svmPrediction = [math.floor(0.5+pred) for pred in svmPrediction]\n","print(\"CoAID_only: Results of SVM internal validation:\")\n","print(classification_report(y_test_base, svmPrediction))\n","\n","svmValidationPrediction = svmClassifier.predict(validationX)\n","svmValidationPrediction = [math.floor(0.5+pred) for pred in svmValidationPrediction]\n","print(\"CoAID_only: Results of SVM external validation, on our new dataset:\")\n","print(classification_report(validationY, svmValidationPrediction))\n","\n","\n","\n","X_train = [one_hot(str(elem), 10000) for elem in X_train_base]\n","X_test =  [one_hot(str(elem), 10000) for elem in X_test_base]\n","X_train = pad_sequences(X_train, padding='post', maxlen=500)\n","X_test = pad_sequences(X_test, padding='post', maxlen=500)\n","\n","lrClassifier = LogisticRegression(random_state=0, max_iter=500)\n","lrClassifier.fit(X_train, y_train_base)\n","lrPrediction = lrClassifier.predict(X_test)\n","lrPrediction = [math.floor(0.5+pred) for pred in lrPrediction]\n","print(\"CoAID_only: Results of LR internal validation:\")\n","print(classification_report(y_test_base, lrPrediction))\n","\n","lrValidationPrediction = lrClassifier.predict(validationX)\n","lrValidationPrediction = [math.floor(0.5+pred) for pred in lrValidationPrediction]\n","print(\"CoAID_only: Results of LR external validation, on our new dataset:\")\n","print(classification_report(validationY, lrValidationPrediction))\n","\n","X_train = [one_hot(str(elem), 10000) for elem in X_train_base]\n","X_test =  [one_hot(str(elem), 10000) for elem in X_test_base]\n","X_train = pad_sequences(X_train, padding='post', maxlen=500)\n","X_test = pad_sequences(X_test, padding='post', maxlen=500)\n","\n","bnbClassifier = BernoulliNB()\n","bnbClassifier.fit(X_train, y_train_base)\n","bnbPrediction = bnbClassifier.predict(X_test)\n","bnbPrediction = [math.floor(0.5+pred) for pred in bnbPrediction]\n","print(\"CoAID_only: Results of Bernoulli NB internal validation:\")\n","print(classification_report(y_test_base, bnbPrediction))\n","bnbValidationPrediction = bnbClassifier.predict(validationX)\n","bnbValidationPrediction = [math.floor(0.5+pred) for pred in bnbValidationPrediction]\n","print(\"CoAID_only: Results of Bernoulli NB external validation, on our new dataset:\")\n","print(classification_report(validationY, bnbValidationPrediction))\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMMxbL8cUIgt+V373C35uw0","collapsed_sections":[],"name":"1]_CoAID_only","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
