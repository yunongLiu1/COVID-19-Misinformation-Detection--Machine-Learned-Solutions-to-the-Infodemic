{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"colab_type":"code","executionInfo":{"elapsed":22035,"status":"ok","timestamp":1598814974418,"user":{"displayName":"Nikhil L Kolluri","photoUrl":"","userId":"01149428014947466640"},"user_tz":300},"id":"n6f8utMiJUie","outputId":"e7e9d8f9-4eff-4652-ee05-f607cb6d5813"},"outputs":[{"name":"stdout","output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":2797,"status":"ok","timestamp":1598814978297,"user":{"displayName":"Nikhil L Kolluri","photoUrl":"","userId":"01149428014947466640"},"user_tz":300},"id":"_UAmhKsRJWvN"},"outputs":[],"source":["from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","\n","# Place dataset path here\n","FNNpath = \"../Datasets/FNN Titles/\"\n","CoAIDpath = \"../Datasets/CoAID/\"\n","\n","\n","politiFactFake = pd.read_csv(FNNpath+\"politifact_fake.csv\", usecols=['title'])\n","politiFactFake['label']=0\n","gossipCopFake = pd.read_csv(FNNpath+\"gossipcop_fake.csv\", usecols=['title'])\n","gossipCopFake['label']=0\n","politiFactTrue = pd.read_csv(FNNpath+\"politifact_real.csv\", usecols=['title'], nrows=len(politiFactFake.values))\n","politiFactTrue['label']=1\n","gossipCopTrue = pd.read_csv(FNNpath+\"gossipcop_real.csv\", usecols=['title'],  nrows=len(gossipCopFake.values))\n","gossipCopTrue['label']=1\n","\n","CoAIDFalse = pd.read_csv(CoAIDpath+\"NewsFakeCOVID-19.csv\", usecols=['title'])\n","CoAIDFalse['label']=0\n","CoAIDTrue = pd.read_csv(CoAIDpath+\"NewsRealCOVID-19.csv\", usecols=['title'], nrows=len(CoAIDFalse.values))\n","CoAIDTrue['label']=1\n","\n","\n","dfTotal = pd.concat([politiFactTrue, gossipCopTrue, politiFactFake, gossipCopFake, CoAIDTrue, CoAIDFalse])\n","X = dfTotal['title'].values\n","y = dfTotal['label'].values\n","\n","X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(\n","  X, y, test_size=0.25, random_state=450)\n","\n","\n","\n","path_external = \"/content/drive/MyDrive/CoVerifi&MedVerifi/\" # Replace with appropriate path\n","validationNewsDF = pd.read_csv(path_external+\"Combined_News.csv\", usecols=['title', 'label'])\n","\n","\n","def binaryLabel(label):\n","  if label == \"TRUE\":\n","    return 1\n","  return 0\n","\n","validationNewsDF['label'] = validationNewsDF['label'].apply(lambda label: binaryLabel(str(label)))\n","\n","validationX = validationNewsDF['title'].values\n","validationX = [one_hot(str(elem),10000) for elem in validationX]\n","validationX = pad_sequences(validationX, padding='post', maxlen=500)\n","validationY = validationNewsDF['label'].values"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":168774,"status":"ok","timestamp":1598815149581,"user":{"displayName":"Nikhil L Kolluri","photoUrl":"","userId":"01149428014947466640"},"user_tz":300},"id":"WEAzEMT3PJet","outputId":"5d57bc98-3b34-4805-897b-08f17745033c"},"outputs":[{"name":"stdout","output_type":"stream","text":["CoAID_and_all_of_FNN: Results of SVM internal validation:\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.47      0.50      1557\n","           1       0.54      0.60      0.56      1607\n","\n","    accuracy                           0.53      3164\n","   macro avg       0.53      0.53      0.53      3164\n","weighted avg       0.53      0.53      0.53      3164\n","\n","CoAID_and_all_of_FNN: Results of SVM external validation, on our new dataset:\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.57      0.61      3883\n","           1       0.55      0.63      0.58      3175\n","\n","    accuracy                           0.60      7058\n","   macro avg       0.60      0.60      0.60      7058\n","weighted avg       0.61      0.60      0.60      7058\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"name":"stdout","output_type":"stream","text":["CoAID_and_all_of_FNN: Results of LR internal validation:\n","              precision    recall  f1-score   support\n","\n","           0       0.51      0.56      0.54      1557\n","           1       0.53      0.48      0.51      1607\n","\n","    accuracy                           0.52      3164\n","   macro avg       0.52      0.52      0.52      3164\n","weighted avg       0.52      0.52      0.52      3164\n","\n","CoAID_and_all_of_FNN: Results of LR external validation, on our new dataset:\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.62      0.61      3883\n","           1       0.52      0.50      0.51      3175\n","\n","    accuracy                           0.57      7058\n","   macro avg       0.56      0.56      0.56      7058\n","weighted avg       0.57      0.57      0.57      7058\n","\n","CoAID_and_all_of_FNN: Results of Bernoulli NB internal validation:\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.29      0.37      1557\n","           1       0.52      0.75      0.62      1607\n","\n","    accuracy                           0.52      3164\n","   macro avg       0.53      0.52      0.49      3164\n","weighted avg       0.53      0.52      0.50      3164\n","\n","CoAID_and_all_of_FNN: Results of Bernoulli NB external validation, on our new dataset:\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.50      0.61      3883\n","           1       0.57      0.82      0.67      3175\n","\n","    accuracy                           0.64      7058\n","   macro avg       0.67      0.66      0.64      7058\n","weighted avg       0.68      0.64      0.64      7058\n","\n"]}],"source":["#For SVM, LR, and NB, we used the default settings provided in the scikit-learn \n","#For CNN we use the standard implementation with default setting https://github.com/dennybritz/cnn-text-classification-tf\n","#Could just use an out-of-the-box CNN implementation from a TF tutorial\n","# The dennybritz one seems good but I can do it later\n","from sklearn import svm\n","from sklearn.linear_model import LogisticRegression\n","from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.metrics import classification_report\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n","# Bernoulli was best of above\n","import math\n","X_train = [one_hot(str(elem), 10000) for elem in X_train_base]\n","X_test =  [one_hot(str(elem), 10000) for elem in X_test_base]\n","X_train = pad_sequences(X_train, padding='post', maxlen=500)\n","X_test = pad_sequences(X_test, padding='post', maxlen=500)\n","\n","svmClassifier = svm.SVC()\n","svmClassifier.fit(X_train, y_train_base)\n","svmPrediction = svmClassifier.predict(X_test)\n","svmPrediction = [math.floor(0.5+pred) for pred in svmPrediction]\n","print(\"CoAID_and_all_of_FNN: Results of SVM internal validation:\")\n","print(classification_report(y_test_base, svmPrediction))\n","\n","svmValidationPrediction = svmClassifier.predict(validationX)\n","svmValidationPrediction = [math.floor(0.5+pred) for pred in svmValidationPrediction]\n","print(\"CoAID_and_all_of_FNN: Results of SVM external validation, on our new dataset:\")\n","print(classification_report(validationY, svmValidationPrediction))\n","\n","\n","\n","X_train = [one_hot(str(elem), 10000) for elem in X_train_base]\n","X_test =  [one_hot(str(elem), 10000) for elem in X_test_base]\n","X_train = pad_sequences(X_train, padding='post', maxlen=500)\n","X_test = pad_sequences(X_test, padding='post', maxlen=500)\n","\n","lrClassifier = LogisticRegression(random_state=0, max_iter=500)\n","lrClassifier.fit(X_train, y_train_base)\n","lrPrediction = lrClassifier.predict(X_test)\n","lrPrediction = [math.floor(0.5+pred) for pred in lrPrediction]\n","print(\"CoAID_and_all_of_FNN: Results of LR internal validation:\")\n","print(classification_report(y_test_base, lrPrediction))\n","\n","lrValidationPrediction = lrClassifier.predict(validationX)\n","lrValidationPrediction = [math.floor(0.5+pred) for pred in lrValidationPrediction]\n","print(\"CoAID_and_all_of_FNN: Results of LR external validation, on our new dataset:\")\n","print(classification_report(validationY, lrValidationPrediction))\n","\n","X_train = [one_hot(str(elem), 10000) for elem in X_train_base]\n","X_test =  [one_hot(str(elem), 10000) for elem in X_test_base]\n","X_train = pad_sequences(X_train, padding='post', maxlen=500)\n","X_test = pad_sequences(X_test, padding='post', maxlen=500)\n","\n","bnbClassifier = BernoulliNB()\n","bnbClassifier.fit(X_train, y_train_base)\n","bnbPrediction = bnbClassifier.predict(X_test)\n","bnbPrediction = [math.floor(0.5+pred) for pred in bnbPrediction]\n","print(\"CoAID_and_all_of_FNN: Results of Bernoulli NB internal validation:\")\n","print(classification_report(y_test_base, bnbPrediction))\n","bnbValidationPrediction = bnbClassifier.predict(validationX)\n","bnbValidationPrediction = [math.floor(0.5+pred) for pred in bnbValidationPrediction]\n","print(\"CoAID_and_all_of_FNN: Results of Bernoulli NB external validation, on our new dataset:\")\n","print(classification_report(validationY, bnbValidationPrediction))\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPClXQNvGPqmhomhn5UcSqf","collapsed_sections":[],"name":"2]_CoAID_and_all_of_FNN","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
