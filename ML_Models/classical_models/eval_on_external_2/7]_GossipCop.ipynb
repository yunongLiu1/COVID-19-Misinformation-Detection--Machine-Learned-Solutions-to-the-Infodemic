{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcVznP9Ow2IC",
        "outputId": "0d2a6305-b291-4a5a-92de-17ec0b4d912e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEu4oPKzw4u2"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "FNNpath = \"../Datasets/FNN Titles/\"\n",
        "gossipCopFake = pd.read_csv(FNNpath+\"gossipcop_fake.csv\", usecols=['title'])\n",
        "gossipCopFake['label']=0\n",
        "gossipCopTrue = pd.read_csv(FNNpath+\"gossipcop_real.csv\", usecols=['title'],  nrows=len(gossipCopFake.values))\n",
        "gossipCopTrue['label']=1\n",
        "\n",
        "\n",
        "\n",
        "dfTotal = pd.concat([gossipCopTrue, gossipCopFake])\n",
        "X = dfTotal['title'].values\n",
        "y = dfTotal['label'].values\n",
        "\n",
        "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(\n",
        "  X, y, test_size=0.25, random_state=450)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-59NkP_BCV52"
      },
      "source": [
        "## Validation on the second external validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXYY0eGnCZTE",
        "outputId": "9d102f0c-4db8-478f-d8b5-ebf71e2d745b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GossipCop: Results of SVM internal validation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.57      0.55      1291\n",
            "           1       0.57      0.54      0.55      1371\n",
            "\n",
            "    accuracy                           0.55      2662\n",
            "   macro avg       0.55      0.55      0.55      2662\n",
            "weighted avg       0.55      0.55      0.55      2662\n",
            "\n",
            "GossipCop: Results of SVM external validation, on our new dataset:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.52      0.43     14398\n",
            "           1       0.31      0.19      0.24     16232\n",
            "\n",
            "    accuracy                           0.35     30630\n",
            "   macro avg       0.34      0.36      0.33     30630\n",
            "weighted avg       0.34      0.35      0.33     30630\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GossipCop: Results of LR internal validation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.50      0.51      1291\n",
            "           1       0.54      0.56      0.55      1371\n",
            "\n",
            "    accuracy                           0.53      2662\n",
            "   macro avg       0.53      0.53      0.53      2662\n",
            "weighted avg       0.53      0.53      0.53      2662\n",
            "\n",
            "GossipCop: Results of LR external validation, on our new dataset:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.36      0.35     14398\n",
            "           1       0.40      0.37      0.39     16232\n",
            "\n",
            "    accuracy                           0.37     30630\n",
            "   macro avg       0.37      0.37      0.37     30630\n",
            "weighted avg       0.37      0.37      0.37     30630\n",
            "\n",
            "GossipCop: Results of Bernoulli NB internal validation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.46      0.48      1291\n",
            "           1       0.54      0.60      0.57      1371\n",
            "\n",
            "    accuracy                           0.53      2662\n",
            "   macro avg       0.53      0.53      0.53      2662\n",
            "weighted avg       0.53      0.53      0.53      2662\n",
            "\n",
            "GossipCop: Results of Bernoulli NB external validation, on our new dataset:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.20      0.19     14398\n",
            "           1       0.18      0.16      0.17     16232\n",
            "\n",
            "    accuracy                           0.18     30630\n",
            "   macro avg       0.18      0.18      0.18     30630\n",
            "weighted avg       0.18      0.18      0.18     30630\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "validationNewsDF = pd.read_csv('../Datasets/New_External_Validation_Dataset.csv')\n",
        "\n",
        "validationX = validationNewsDF['title'].values\n",
        "validationX = [one_hot(str(elem),10000) for elem in validationX]\n",
        "validationX = pad_sequences(validationX, padding='post', maxlen=500)\n",
        "validationY = validationNewsDF['label'].values\n",
        "\n",
        "#For SVM, LR, and NB, we used the default settings provided in the scikit-learn \n",
        "#For CNN we use the standard implementation with default setting https://github.com/dennybritz/cnn-text-classification-tf\n",
        "#Could just use an out-of-the-box CNN implementation from a TF tutorial\n",
        "# The dennybritz one seems good but I can do it later\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
        "# Bernoulli was best of above\n",
        "import math\n",
        "X_train = [one_hot(str(elem), 10000) for elem in X_train_base]\n",
        "X_test =  [one_hot(str(elem), 10000) for elem in X_test_base]\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=500)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=500)\n",
        "\n",
        "svmClassifier = svm.SVC()\n",
        "svmClassifier.fit(X_train, y_train_base)\n",
        "svmPrediction = svmClassifier.predict(X_test)\n",
        "svmPrediction = [math.floor(0.5+pred) for pred in svmPrediction]\n",
        "print(\"GossipCop: Results of SVM internal validation:\")\n",
        "print(classification_report(y_test_base, svmPrediction))\n",
        "\n",
        "svmValidationPrediction = svmClassifier.predict(validationX)\n",
        "svmValidationPrediction = [math.floor(0.5+pred) for pred in svmValidationPrediction]\n",
        "print(\"GossipCop: Results of SVM external validation, on our new dataset:\")\n",
        "print(classification_report(validationY, svmValidationPrediction))\n",
        "\n",
        "\n",
        "\n",
        "X_train = [one_hot(str(elem), 10000) for elem in X_train_base]\n",
        "X_test =  [one_hot(str(elem), 10000) for elem in X_test_base]\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=500)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=500)\n",
        "\n",
        "lrClassifier = LogisticRegression(random_state=0, max_iter=500)\n",
        "lrClassifier.fit(X_train, y_train_base)\n",
        "lrPrediction = lrClassifier.predict(X_test)\n",
        "lrPrediction = [math.floor(0.5+pred) for pred in lrPrediction]\n",
        "print(\"GossipCop: Results of LR internal validation:\")\n",
        "print(classification_report(y_test_base, lrPrediction))\n",
        "\n",
        "lrValidationPrediction = lrClassifier.predict(validationX)\n",
        "lrValidationPrediction = [math.floor(0.5+pred) for pred in lrValidationPrediction]\n",
        "print(\"GossipCop: Results of LR external validation, on our new dataset:\")\n",
        "print(classification_report(validationY, lrValidationPrediction))\n",
        "\n",
        "X_train = [one_hot(str(elem), 10000) for elem in X_train_base]\n",
        "X_test =  [one_hot(str(elem), 10000) for elem in X_test_base]\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=500)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=500)\n",
        "\n",
        "bnbClassifier = BernoulliNB()\n",
        "bnbClassifier.fit(X_train, y_train_base)\n",
        "bnbPrediction = bnbClassifier.predict(X_test)\n",
        "bnbPrediction = [math.floor(0.5+pred) for pred in bnbPrediction]\n",
        "print(\"GossipCop: Results of Bernoulli NB internal validation:\")\n",
        "print(classification_report(y_test_base, bnbPrediction))\n",
        "bnbValidationPrediction = bnbClassifier.predict(validationX)\n",
        "bnbValidationPrediction = [math.floor(0.5+pred) for pred in bnbValidationPrediction]\n",
        "print(\"GossipCop: Results of Bernoulli NB external validation, on our new dataset:\")\n",
        "print(classification_report(validationY, bnbValidationPrediction))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "7]_GossipCop.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
